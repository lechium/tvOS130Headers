/*
* This header is generated by classdump-dyld 1.0
* on Tuesday, November 5, 2019 at 2:44:53 AM Mountain Standard Time
* Operating System: Version 13.0 (Build 17J586)
* Image Source: /System/Library/PrivateFrameworks/SiriCore.framework/SiriCore
* classdump-dyld is licensed under GPLv3, Copyright Â© 2013-2016 by Elias Limneos.
*/

#import <SiriCore/AFSpeechServiceDelegate.h>

@protocol OS_dispatch_queue, SiriCoreLocalSpeechRecognizerDelegate;
@class NSObject, NSXPCConnection, NSString, NSError, NSData;

@interface SiriCoreLocalSpeechRecognizer : NSObject <AFSpeechServiceDelegate> {

	BOOL _recognitionActive;
	NSObject*<OS_dispatch_queue> _queue;
	NSXPCConnection* _esConnection;
	BOOL _hasRecognizedAnything;
	unsigned char _instanceUUID[16];
	NSString* _currentLanguage;
	NSError* _recognitionError;
	NSString* _preheatedProfileAssetPath;
	NSData* _preheatedProfile;
	id<SiriCoreLocalSpeechRecognizerDelegate> _delegate;

}

@property (nonatomic,__weak,readonly) id<SiriCoreLocalSpeechRecognizerDelegate> delegate;              //@synthesize delegate=_delegate - In the implementation block
@property (readonly) unsigned long long hash; 
@property (readonly) Class superclass; 
@property (copy,readonly) NSString * description; 
@property (copy,readonly) NSString * debugDescription; 
+(id)speechProfileDataLastModifiedDataForLanguage:(id)arg1 ;
+(id)installedAssetSizeWithError:(id*)arg1 ;
+(id)purgeInstalledAssetsWithError:(id*)arg1 ;
-(id)init;
-(void)invalidate;
-(id)_connection;
-(id<SiriCoreLocalSpeechRecognizerDelegate>)delegate;
-(id)_service;
-(void)getOfflineDictationStatusWithCompletion:(/*^block*/id)arg1 ;
-(void)preheatSpeechRecognitionWithLanguage:(id)arg1 ;
-(void)addAudioPacket:(id)arg1 ;
-(void)finishAudio;
-(void)createSpeechProfileWithLanguage:(id)arg1 JSONData:(id)arg2 completion:(/*^block*/id)arg3 ;
-(void)getOfflineDictationStatusIgnoringCache:(BOOL)arg1 withCompletion:(/*^block*/id)arg2 ;
-(void)fetchAssetsForLanguage:(id)arg1 completion:(/*^block*/id)arg2 ;
-(void)fetchUserDataForLanguage:(id)arg1 completion:(/*^block*/id)arg2 ;
-(void)runAdaptationRecipeEvaluation:(id)arg1 recordData:(id)arg2 attachments:(id)arg3 completion:(/*^block*/id)arg4 ;
-(void)writeDESRecord;
-(oneway void)speechServiceDidRecognizeTokens:(id)arg1 ;
-(oneway void)speechServiceDidProcessAudioDuration:(double)arg1 ;
-(oneway void)speechServiceDidRecognizeRawEagerRecognitionCandidate:(id)arg1 ;
-(oneway void)speechServiceDidRecognizePackage:(id)arg1 ;
-(oneway void)speechServiceDidFinishRecognitionWithStatistics:(id)arg1 error:(id)arg2 ;
-(id)_newConnection;
-(void)_readProfileAndUserDataWithLanguage:(id)arg1 allowOverride:(BOOL)arg2 completion:(/*^block*/id)arg3 ;
-(id)_serviceWithFunctionName:(id)arg1 errorHandler:(/*^block*/id)arg2 ;
-(id)initWithDelegate:(id)arg1 instanceUUID:(unsigned char)arg2 ;
-(id)_synchronousServiceWithErrorHandler:(/*^block*/id)arg1 ;
-(void)startSpeechRecognitionWithLanguage:(id)arg1 task:(id)arg2 context:(id)arg3 narrowband:(BOOL)arg4 detectUtterances:(BOOL)arg5 maximumRecognitionDuration:(double)arg6 farField:(BOOL)arg7 secureOfflineOnly:(BOOL)arg8 censorSpeech:(BOOL)arg9 originalAudioFileURL:(id)arg10 overrides:(id)arg11 modelOverrideURL:(id)arg12 didStartHandler:(/*^block*/id)arg13 ;
-(void)updateSpeechProfileWithLanguage:(id)arg1 completion:(/*^block*/id)arg2 ;
-(void)resetDESWithCompletion:(/*^block*/id)arg1 ;
@end

